Usuario â”€â–¶ Frontend (Flask)
            â”‚
            â–¼
         API (FastAPI)
            â”‚
            â–¼
        Retriever + FAISS
            â”‚
            â”œâ”€ Ollama (modo local)
            â””â”€ OpenAI/Gemini (modo API)

Backend Team

El equipo de backend trabajÃ³ en los servicios:

API (FastAPI): endpoint /ask con la lÃ³gica RAG (consulta â†’ recuperaciÃ³n â†’ respuesta).

Retriever: mÃ³dulo encargado de vectorizar documentos (ingest.py), gestionar FAISS y responder a /search.

Benchmarks: pruebas de latencia y rendimiento en benchmarks/latency_check.py.

Contenedores: configuraron los Dockerfiles y variables .env para cada entorno (local y api).

ðŸ”¹ Frontend Team

El equipo de frontend desarrollÃ³ dos versiones en Flask:

frontend_local â†’ interfaz para el modelo local (Ollama).

frontend_api â†’ interfaz para modelos externos (OpenAI/Gemini).
Ambas consumen la API REST (/ask) y muestran las respuestas al usuario de forma simple y responsiva.

ðŸ”¹ IntegraciÃ³n y ColaboraciÃ³n

Ambos equipos trabajaron sobre la misma base de datos de vectores (FAISS + documentos en docs/).

La comunicaciÃ³n entre servicios se hizo vÃ­a HTTP REST, con endpoints estandarizados (/ask, /search, /health).

Se usaron perfiles de Docker Compose (local y api) para probar las dos versiones completas sin conflicto.

El desarrollo se coordinÃ³ mediante ramas compartidas (backend/ y frontend/), asegurando compatibilidad continua.